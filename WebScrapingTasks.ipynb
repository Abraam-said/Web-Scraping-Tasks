{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1\n",
    "---------\n",
    "Scrap the USD To EGP Exchange rate from this website\n",
    "https://www.exchangerates.org.uk/Dollars-to-Egyptian-Pounds-currency-conversion-page.html\n",
    "and then use it to make a software that takes amount of USD Dollars from the user and calculate how much will it cost in EGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30427.5\n"
     ]
    }
   ],
   "source": [
    "dollars = int(input())\n",
    "req = requests.request('GET', 'https://www.exchangerates.org.uk/Dollars-to-Egyptian-Pounds-currency-conversion-page.html')\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "exchange_rate = soup.find(\"span\", {\"id\":\"shd2b;\"})\n",
    "print(dollars * float(exchange_rate.text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2\n",
    "--------- \n",
    "Scraping from forecast weather\n",
    "Imagine you work for forecast weather Now imagine your boss wants you to find the temperature for each day in celsius degree. How could you do this with Beautiful Soup?\n",
    "https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  Friday\n",
      "  <br/>\n",
      "  Night\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"Friday Night: Partly cloudy, with a low around 42.\" class=\"forecast-icon\" src=\"newimages/medium/nsct.png\" title=\"Friday Night: Partly cloudy, with a low around 42.\"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Partly Cloudy\n",
      " </p>\n",
      " <p class=\"temp temp-low\">\n",
      "  Low: 42 °F\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "req = requests.request('GET', 'https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.Y-QGZi9BxPY')\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "seven_days = soup.find(id = \"seven-day-forecast-body\")\n",
    "item = seven_days.find_all('div', class_='tombstone-container' )\n",
    "print(item[5].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunny = (item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Low: 41 °F'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = sunny.find('p', class_='period-name').text\n",
    "short_desc = sunny.find('p', class_='short-desc').text\n",
    "temp = sunny.find('p', class_='temp').text\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 58, 43, 60, 42, 61, 42, 62]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "periods = [sunny.find('p', class_='period-name').text for sunny in item]\n",
    "short_desc = [sunny.find('p', class_='short-desc').text for sunny in item]\n",
    "temps = [int(sunny.find('p', class_='temp').text.split()[1]) for sunny in item]\n",
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'periods': periods,\n",
    "    'short_desc': short_desc,\n",
    "    'temps':temps\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periods</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>temps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Partly Sunny</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         periods     short_desc  temps\n",
       "0        Tonight   Mostly Clear     41\n",
       "1       Thursday   Partly Sunny     58\n",
       "2  ThursdayNight  Mostly Cloudy     43\n",
       "3         Friday  Mostly Cloudy     60\n",
       "4    FridayNight  Partly Cloudy     42\n",
       "5       Saturday          Sunny     61\n",
       "6  SaturdayNight   Mostly Clear     42\n",
       "7         Sunday   Mostly Sunny     62"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('name.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "---------\n",
    "Scrap the books (name, price, rate) for each category and put them into a CSV & Excel file\n",
    "https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.request('GET', url)\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "number_of_books = int(soup.find('form', class_='form-horizontal').find('strong').text)\n",
    "number_of_pages = (number_of_books//20)+1\n",
    "number_of_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://books.toscrape.com/catalogue/category/books/historical-fiction_4/index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Travel page\n",
      "Scraping Mystery page\n",
      "Scraping Historical Fiction page\n",
      "Scraping Sequential Art page\n",
      "Scraping Classics page\n",
      "Scraping Philosophy page\n",
      "Scraping Romance page\n",
      "Scraping Womens Fiction page\n",
      "Scraping Fiction page\n",
      "Scraping Childrens page\n",
      "Scraping Religion page\n",
      "Scraping Nonfiction page\n",
      "Scraping Music page\n",
      "Scraping Default page\n",
      "Scraping Science Fiction page\n",
      "Scraping Sports and Games page\n",
      "Scraping Add a comment page\n",
      "Scraping Fantasy page\n",
      "Scraping New Adult page\n",
      "Scraping Young Adult page\n",
      "Scraping Science page\n",
      "Scraping Poetry page\n",
      "Scraping Paranormal page\n",
      "Scraping Art page\n",
      "Scraping Psychology page\n",
      "Scraping Autobiography page\n",
      "Scraping Parenting page\n",
      "Scraping Adult Fiction page\n",
      "Scraping Humor page\n",
      "Scraping Horror page\n",
      "Scraping History page\n",
      "Scraping Food and Drink page\n",
      "Scraping Christian Fiction page\n",
      "Scraping Business page\n",
      "Scraping Biography page\n",
      "Scraping Thriller page\n",
      "Scraping Contemporary page\n",
      "Scraping Spirituality page\n",
      "Scraping Academic page\n",
      "Scraping Self Help page\n",
      "Scraping Historical page\n",
      "Scraping Christian page\n",
      "Scraping Suspense page\n",
      "Scraping Short Stories page\n",
      "Scraping Novels page\n",
      "Scraping Health page\n",
      "Scraping Politics page\n",
      "Scraping Cultural page\n",
      "Scraping Erotica page\n",
      "Scraping Crime page\n"
     ]
    }
   ],
   "source": [
    "# work with each url\n",
    "data = {\n",
    "    'name': [],\n",
    "    'price': [],\n",
    "    'rating': [],\n",
    "    'category': []\n",
    "}\n",
    "def scrap_page(url):\n",
    "    req = requests.request('GET', url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    articles = soup.find_all('article', class_='product_pod')\n",
    "    for article in articles: \n",
    "        data['name'].append(article.find('h3').text)\n",
    "        data['price'].append(article.find('div', class_=\"product_price\").find('p', class_='price_color').text)\n",
    "        data['rating'].append( article.find('p').attrs['class'][-1])\n",
    "        data['category'].append(category_name)\n",
    "# access main page\n",
    "req = requests.request('GET', \"https://books.toscrape.com/\")\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "# get urls of catagories\n",
    "categories = soup.find('div', attrs={\n",
    "    'class': 'side_categories'\n",
    "    }).find_all('ul')[1].find_all('a')\n",
    "\n",
    "# go for each url scrap book inside it\n",
    "for category in categories:\n",
    "    \n",
    "    # get url of each page\n",
    "    url = f'https://books.toscrape.com/{category.attrs[\"href\"]}'\n",
    "    category_name = category.text.strip()\n",
    "    print(f'Scraping {category_name} page')\n",
    "    \n",
    "    \n",
    "    req = requests.request('GET', url)\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "    try:\n",
    "        number_of_books = (soup.find('li', class_='current').text)\n",
    "        int(number_of_books.replace('\\n', \"\").split(\"of\")[1].strip())\n",
    "        for i in range(1, number_of_pages+1):\n",
    "            page_num = f\"page-{number_of_pages}.html\"\n",
    "            url = url.replace('index', page_num)\n",
    "        scrap_page(url)\n",
    "    except:\n",
    "        number_of_pages = 1\n",
    "        scrap_page(url)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Travel'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>Two</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Moon over Noah’s ...</td>\n",
       "      <td>£49.43</td>\n",
       "      <td>Four</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>See America: A Celebration ...</td>\n",
       "      <td>£48.87</td>\n",
       "      <td>Three</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vagabonding: An Uncommon Guide ...</td>\n",
       "      <td>£36.94</td>\n",
       "      <td>Two</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under the Tuscan Sun</td>\n",
       "      <td>£37.33</td>\n",
       "      <td>Three</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Why the Right Went ...</td>\n",
       "      <td>£52.65</td>\n",
       "      <td>Four</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Equal Is Unfair: America's ...</td>\n",
       "      <td>£56.86</td>\n",
       "      <td>One</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Amid the Chaos</td>\n",
       "      <td>£36.58</td>\n",
       "      <td>One</td>\n",
       "      <td>Cultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Dark Notes</td>\n",
       "      <td>£19.19</td>\n",
       "      <td>Five</td>\n",
       "      <td>Erotica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>The Long Shadow of ...</td>\n",
       "      <td>£10.97</td>\n",
       "      <td>One</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name   price rating  category\n",
       "0               It's Only the Himalayas  £45.17    Two    Travel\n",
       "1             Full Moon over Noah’s ...  £49.43   Four    Travel\n",
       "2        See America: A Celebration ...  £48.87  Three    Travel\n",
       "3    Vagabonding: An Uncommon Guide ...  £36.94    Two    Travel\n",
       "4                  Under the Tuscan Sun  £37.33  Three    Travel\n",
       "..                                  ...     ...    ...       ...\n",
       "272              Why the Right Went ...  £52.65   Four  Politics\n",
       "273      Equal Is Unfair: America's ...  £56.86    One  Politics\n",
       "274                      Amid the Chaos  £36.58    One  Cultural\n",
       "275                          Dark Notes  £19.19   Five   Erotica\n",
       "276              The Long Shadow of ...  £10.97    One     Crime\n",
       "\n",
       "[277 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "---------\n",
    "Use this web service \n",
    "https://jsonplaceholder.typicode.com/users\n",
    "and make a program that get all users data including name, username, email, street, suite, city, zip code, geo_lat & geo_long and then save them in a CSV & Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'name': 'Leanne Graham',\n",
       " 'username': 'Bret',\n",
       " 'email': 'Sincere@april.biz',\n",
       " 'address': {'street': 'Kulas Light',\n",
       "  'suite': 'Apt. 556',\n",
       "  'city': 'Gwenborough',\n",
       "  'zipcode': '92998-3874',\n",
       "  'geo': {'lat': '-37.3159', 'lng': '81.1496'}},\n",
       " 'phone': '1-770-736-8031 x56442',\n",
       " 'website': 'hildegard.org',\n",
       " 'company': {'name': 'Romaguera-Crona',\n",
       "  'catchPhrase': 'Multi-layered client-server neural-net',\n",
       "  'bs': 'harness real-time e-markets'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://jsonplaceholder.typicode.com/users'\n",
    "req = requests.request('GET', url)\n",
    "data = req.json()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    headers = ['name', ' username', 'email', 'phone', 'website', 'company_name', ' street', 'suite', 'city', 'zipcode', 'geo_lat', 'geo_lng']\n",
    "    writer.writerow(headers)\n",
    "    for user in data:\n",
    "        name  = user['name']\n",
    "        username = user['username']\n",
    "        email = user['email']\n",
    "        phone = user['phone']\n",
    "        website = user['website']\n",
    "        company_name = user['company']['name']\n",
    "        street = user['address']['street']\n",
    "        suite = user['address']['suite']\n",
    "        city = user['address']['city']\n",
    "        zip_code = user['address']['zipcode']\n",
    "        geo_lat = user['address']['geo']['lat']\n",
    "        geo_lng = user['address']['geo']['lng']\n",
    "        data = [name,username, email,phone,website,company_name, street, suite,city, zip_code,geo_lat,geo_lng]\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>company_name</th>\n",
       "      <th>street</th>\n",
       "      <th>suite</th>\n",
       "      <th>city</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geo_lat</th>\n",
       "      <th>geo_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>1-770-736-8031 x56442</td>\n",
       "      <td>hildegard.org</td>\n",
       "      <td>Romaguera-Crona</td>\n",
       "      <td>Kulas Light</td>\n",
       "      <td>Apt. 556</td>\n",
       "      <td>Gwenborough</td>\n",
       "      <td>92998-3874</td>\n",
       "      <td>-37.3159</td>\n",
       "      <td>81.1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Antonette</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>010-692-6593 x09125</td>\n",
       "      <td>anastasia.net</td>\n",
       "      <td>Deckow-Crist</td>\n",
       "      <td>Victor Plains</td>\n",
       "      <td>Suite 879</td>\n",
       "      <td>Wisokyburgh</td>\n",
       "      <td>90566-7771</td>\n",
       "      <td>-43.9509</td>\n",
       "      <td>-34.4618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>1-463-123-4447</td>\n",
       "      <td>ramiro.info</td>\n",
       "      <td>Romaguera-Jacobson</td>\n",
       "      <td>Douglas Extension</td>\n",
       "      <td>Suite 847</td>\n",
       "      <td>McKenziehaven</td>\n",
       "      <td>59590-4157</td>\n",
       "      <td>-68.6102</td>\n",
       "      <td>-47.0653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Karianne</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>493-170-9623 x156</td>\n",
       "      <td>kale.biz</td>\n",
       "      <td>Robel-Corkery</td>\n",
       "      <td>Hoeger Mall</td>\n",
       "      <td>Apt. 692</td>\n",
       "      <td>South Elvis</td>\n",
       "      <td>53919-4257</td>\n",
       "      <td>29.4572</td>\n",
       "      <td>-164.2990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Kamren</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>(254)954-1289</td>\n",
       "      <td>demarco.info</td>\n",
       "      <td>Keebler LLC</td>\n",
       "      <td>Skiles Walks</td>\n",
       "      <td>Suite 351</td>\n",
       "      <td>Roscoeview</td>\n",
       "      <td>33263</td>\n",
       "      <td>-31.8129</td>\n",
       "      <td>62.5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Leopoldo_Corkery</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>1-477-935-8478 x6430</td>\n",
       "      <td>ola.org</td>\n",
       "      <td>Considine-Lockman</td>\n",
       "      <td>Norberto Crossing</td>\n",
       "      <td>Apt. 950</td>\n",
       "      <td>South Christy</td>\n",
       "      <td>23505-1337</td>\n",
       "      <td>-71.4197</td>\n",
       "      <td>71.7478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Elwyn.Skiles</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>210.067.6132</td>\n",
       "      <td>elvis.io</td>\n",
       "      <td>Johns Group</td>\n",
       "      <td>Rex Trail</td>\n",
       "      <td>Suite 280</td>\n",
       "      <td>Howemouth</td>\n",
       "      <td>58804-1099</td>\n",
       "      <td>24.8918</td>\n",
       "      <td>21.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Maxime_Nienow</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>586.493.6943 x140</td>\n",
       "      <td>jacynthe.com</td>\n",
       "      <td>Abernathy Group</td>\n",
       "      <td>Ellsworth Summit</td>\n",
       "      <td>Suite 729</td>\n",
       "      <td>Aliyaview</td>\n",
       "      <td>45169</td>\n",
       "      <td>-14.3990</td>\n",
       "      <td>-120.7677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>(775)976-6794 x41206</td>\n",
       "      <td>conrad.com</td>\n",
       "      <td>Yost and Sons</td>\n",
       "      <td>Dayna Park</td>\n",
       "      <td>Suite 449</td>\n",
       "      <td>Bartholomebury</td>\n",
       "      <td>76495-3109</td>\n",
       "      <td>24.6463</td>\n",
       "      <td>-168.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Moriah.Stanton</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>024-648-3804</td>\n",
       "      <td>ambrose.net</td>\n",
       "      <td>Hoeger LLC</td>\n",
       "      <td>Kattie Turnpike</td>\n",
       "      <td>Suite 198</td>\n",
       "      <td>Lebsackbury</td>\n",
       "      <td>31428-2261</td>\n",
       "      <td>-38.2386</td>\n",
       "      <td>57.2232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name          username                      email  \\\n",
       "0             Leanne Graham              Bret          Sincere@april.biz   \n",
       "1              Ervin Howell         Antonette          Shanna@melissa.tv   \n",
       "2          Clementine Bauch          Samantha         Nathan@yesenia.net   \n",
       "3          Patricia Lebsack          Karianne  Julianne.OConner@kory.org   \n",
       "4          Chelsey Dietrich            Kamren   Lucio_Hettinger@annie.ca   \n",
       "5      Mrs. Dennis Schulist  Leopoldo_Corkery    Karley_Dach@jasper.info   \n",
       "6           Kurtis Weissnat      Elwyn.Skiles     Telly.Hoeger@billy.biz   \n",
       "7  Nicholas Runolfsdottir V     Maxime_Nienow       Sherwood@rosamond.me   \n",
       "8           Glenna Reichert          Delphine    Chaim_McDermott@dana.io   \n",
       "9        Clementina DuBuque    Moriah.Stanton     Rey.Padberg@karina.biz   \n",
       "\n",
       "                   phone        website        company_name  \\\n",
       "0  1-770-736-8031 x56442  hildegard.org     Romaguera-Crona   \n",
       "1    010-692-6593 x09125  anastasia.net        Deckow-Crist   \n",
       "2         1-463-123-4447    ramiro.info  Romaguera-Jacobson   \n",
       "3      493-170-9623 x156       kale.biz       Robel-Corkery   \n",
       "4          (254)954-1289   demarco.info         Keebler LLC   \n",
       "5   1-477-935-8478 x6430        ola.org   Considine-Lockman   \n",
       "6           210.067.6132       elvis.io         Johns Group   \n",
       "7      586.493.6943 x140   jacynthe.com     Abernathy Group   \n",
       "8   (775)976-6794 x41206     conrad.com       Yost and Sons   \n",
       "9           024-648-3804    ambrose.net          Hoeger LLC   \n",
       "\n",
       "              street      suite            city     zipcode  geo_lat   geo_lng  \n",
       "0        Kulas Light   Apt. 556     Gwenborough  92998-3874 -37.3159   81.1496  \n",
       "1      Victor Plains  Suite 879     Wisokyburgh  90566-7771 -43.9509  -34.4618  \n",
       "2  Douglas Extension  Suite 847   McKenziehaven  59590-4157 -68.6102  -47.0653  \n",
       "3        Hoeger Mall   Apt. 692     South Elvis  53919-4257  29.4572 -164.2990  \n",
       "4       Skiles Walks  Suite 351      Roscoeview       33263 -31.8129   62.5342  \n",
       "5  Norberto Crossing   Apt. 950   South Christy  23505-1337 -71.4197   71.7478  \n",
       "6          Rex Trail  Suite 280       Howemouth  58804-1099  24.8918   21.8984  \n",
       "7   Ellsworth Summit  Suite 729       Aliyaview       45169 -14.3990 -120.7677  \n",
       "8         Dayna Park  Suite 449  Bartholomebury  76495-3109  24.6463 -168.8889  \n",
       "9    Kattie Turnpike  Suite 198     Lebsackbury  31428-2261 -38.2386   57.2232  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('user.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e4bcfdbc3e3fc431ba0a748b76af9a5e6d7f0e4acd90ce15c18ac3eb4ebef31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
